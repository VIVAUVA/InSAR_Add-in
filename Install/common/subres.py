"""
This module implements the subsidence analysis algorithm developed by VIVA.

The technique is fully described in the following paper (available for download
`here <http://viva-lab.ece.virginia.edu/foswiki/bin/view/InSAR/PublicationOutreach>`_):

Vaccari, A.; Stuecheli, M.; Bruckno, B.; Hoppe, E.; Acton, S.T.;
**"Detection of geophysical features in InSAR point cloud data sets using
spatiotemporal models,"** *International Journal of Remote Sensing,* vol.34,
no.22, pp.8215-8234. doi: `10.1080/01431161.2013.833357
<http://dx.doi.org/10.1080/01431161.2013.833357>`_.

.. note::
    The current implementation is not optimized for execution speed and is made
    available for demonstration purpose only. The parameters are automatically
    evaluated and the user should be careful not to select more than a few
    hundred scatterers since computational times can be quite long.
"""

# Try to import *arcpy* (provided by ArcGIS)
try:
    import arcpy as ap
except ImportError as e:
    print(e.message)
    raise

# Try to import *pythonaddins* (provided by ArcGIS)
try:
    import pythonaddins as pa
except ImportError as e:
    print(e.message)
    raise

# Try to import *numpy* (should be provided by ArcGIS as well)
try:
    import numpy as np
except ImportError as e:
    pa.MessageBox(e.message, "Error", 0)
    raise

# Try to import the *regular expression* package
try:
    import re
except ImportError as e:
    pa.MessageBox(e.message, "Error", 0)
    raise

# Try to import the the *datetime* package
try:
    from datetime import datetime as dt
except ImportError as e:
    pa.MessageBox(e.message, "Error", 0)
    raise

# Try to import the *itertools* package
try:
    import itertools as it
except ImportError as e:
    pa.MessageBox(e.message, "Error", 0)
    raise


def evaluate(extent, layer):
    """
    This function creates a raster where each cell represents the minimum value
    of the residual (difference) between various models of subsidence centered
    at the cell location and the SqueeSAR dataset. For each location, several
    spatio-temporal subsidence models are created and for each of the model the
    average difference between predicted and observed displacements is
    evaluated. The raster is generated by taking the minimum residual value
    of every model.

    In the current version, the parameters limits are automatically selected
    (see the source for more information). In future versions, we are planning
    to give the user the option to select the ranges and steps for each of the
    parameters. This requires to move the implementation within the toolbox
    framework.

    .. note::
        TODO:

        - modify the code to take advantage of the "band" structure in the
          raster. Each band should incorporate a "slice" of the
          multi-dimensional residual array: minimum (current returned value),
          propagated residual, sigma, and alpha. (See the paper for more
          details)

    Args:
        extent (Extent): the extent object identifying the user-selected area.

        layer (Layer): a reference to the layer containing the SqueeSAR data.

    Returns:
        propres (float array): the minimum projection of the residual array.
    """

    # Extract field names
    fld = ap.ListFields(layer)
    fld_names = [f.name for f in fld]
    print("Available fields:\n{0}\n".format(fld_names))

    # Extract date fields: DYYYYMMDD
    fld_date = [d.group() for d in (re.match(u"^D([0-9]){8}", name, re.UNICODE) for name in fld_names) if d is not None]
    print("Available date fields:\n{0}\n".format(fld_date))


    # Evaluate intervals between acquisitions
    fld_date_str = [f[1:] for f in fld_date]
    t0 = dt.strptime(fld_date_str[0], "%Y%m%d")
    # Drop the first date since both displacement an time difference are 0
    fld_date = fld_date[1:]
    fld_date_str = fld_date_str[1:]
    tDay = np.asarray([(dt.strptime(d, "%Y%m%d") - t0).days for d in fld_date_str])
    print("Interval between acquisitions (days):\n{0}\n".format(tDay))
    # TODO: If we include the time 0 we are providing a perfect fit which
    #       might introduce a bias in the evaluation lowering the
    #       residual.

    # Store all data in a structured array
    sel_data = ap.da.FeatureClassToNumPyArray(layer, fld_names)

    # Evaluate accumulator limits:
    #   [a0min, a0max, a0steps;
    #    ...
    #    a3min, a3max, a3steps]
    #
    #   a0 is the accumulator x
    #   a1 is the accumulator y
    #   a2 is the accumulator sigma
    #   a3 is the accumulator amplitude
    ar = np.zeros((4, 3))
    ar[0] = [extent.XMin, extent.XMax, 20.0]
    ar[1] = [extent.YMin, extent.YMax, 20.0]
    xy = sel_data[u"Shape"]
    pd = np.sqrt(((xy[:, None, :] - xy) ** 2).sum(-1))
    pd = pd + np.max(pd) * np.eye(len(xy))
    ar[2] = [np.min(pd), np.min((50.0 * np.min(pd), np.min((extent.height, extent.width)))), 10.0]
    cd = np.asarray(sel_data[fld_date].tolist())
    ar[3] = [1.5 * np.min(cd) / np.max(tDay), np.min((0.1, np.max(cd))) / np.max(tDay), 10.0]
    # TODO: the parameter limits and step should be entered by the user and
    #       the selection should include point extending 3*sigma_max out of
    #       the user-selected region.
    #       The range for the amplitude should be negative and, as currently
    #       evaluated can lead to problems: it could be positive and the fit
    #       expects a negative value or, worse, have zero values.
    print("Accumulator limits:\n{0}\n".format(ar))

    # Build accumulator
    xRng = np.linspace(ar[0][0], ar[0][1], ar[0][2])
    yRng = np.linspace(ar[1][0], ar[1][1], ar[1][2])
    sRng = np.linspace(ar[2][0], ar[2][1], ar[2][2])**2
    aRng = np.linspace(ar[3][0], ar[3][1], ar[3][2])

    # Define indexes
    xIdx = range(len(xRng))
    yIdx = range(len(yRng))
    sIdx = range(len(sRng))
    aIdx = range(len(aRng))

    # Define ranges
    cnt = np.zeros((len(xRng), len(yRng), len(sRng), 3))
    acc = np.zeros((len(xRng), len(yRng), len(sRng), len(aRng), 3))
    res = np.zeros((len(xRng), len(yRng), len(sRng), len(aRng)))

    # Iterate through location and sigmas
    for (x, y, s) in it.product(xIdx, yIdx, sIdx):
        print(x, y, s)
        sd = sRng[s]
        cxy = np.asarray((xRng[x], yRng[y]))

        # For each point in the selected area
        for d in sel_data:
            # Extract the point displacements
            dis = np.asarray(np.asarray(d)[fld_date].tolist())

            # Evaluate the distance from the current location
            far = d[u"Shape"] - cxy
            dist = np.inner(far, far)

            # Evaluate if and where it is within 3*sigma
            if dist < 9 * sd:
                if dist < sd:  # sigma
                    rng = 0
                elif dist < 4 * sd: # 2 * sigma
                    rng = 1
                else:  # 3*sigma
                    rng = 2

                # Increase the counter for the range
                cnt[x, y, s, rng] += 1

                # Evaluate the base expected exponential curve
                ex = tDay * np.exp(-dist / (2 * sd))

                # For each growth speed (amplitude)
                for a in aIdx:
                    # Evaluate the modelled subsidence
                    fit = aRng[a] * ex

                    # Calcualte the difference with the actual displacements
                    dif = np.abs(fit - dis)

                    # Add the residual to the accumulator for that combination
                    # of parameters
                    acc[x, y, s, a, rng] += np.average(np.minimum(1.0, dif / np.maximum(np.abs(fit), np.abs(dis))))

        # This loop normalizes the data based on the number of counts for each
        # range and then averages the results to provide the final value
        for a in aIdx:
            nrmAcc = np.zeros(3)

            # For each sigma interval
            for rng in [0, 1, 2]:
                if cnt[x, y, s, rng] == 0:  # If not data => maximum residual
                    nrmAcc[rng] = 1.0
                else:  # If data => normalize by the counts
                    nrmAcc[rng] = acc[x, y, s, a, rng] / cnt[x, y, s, rng]

            # Average the results from the different sigma ranges
            res[x, y, s, a] = np.average(nrmAcc)

    # Evaluate the minimum projection in the spatial coordinates
    prores = np.flipud(np.min(np.min(res, 3), 2))

    return prores






















